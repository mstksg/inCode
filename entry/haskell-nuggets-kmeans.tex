\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.50,0.00}{\textbf{#1}}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{#1}}}}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Justin Le},
            pdftitle={Haskell Nuggets: k-means},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
% Make links footnotes instead of hotlinks:
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\title{Haskell Nuggets: k-means}
\author{Justin Le}
\date{July 26, 2024}

\begin{document}
\maketitle

\emph{Originally posted on
\textbf{\href{https://blog.jle.im/entry/haskell-nuggets-kmeans.html}{in Code}}.}

\documentclass[]{}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage[margin=1in]{geometry}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
% Make links footnotes instead of hotlinks:
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\textbackslash begin\{document\}

AI is hot, so let's talk about some ``classical machine learning'' in Haskell
with k-means clustering! Let's throw in some dependent types too.

There are a bazillion ways of implementing such a simple algorithm, but this is
how \emph{I'd} do it, as someone who develops almost exclusively in Haskell (or
functional pure languages) in both personal projects and work. It's not the
``right'' way or the ``best'' way, but it's the way that brings me joy.
Hopefully it can also break beyond the simple toy projects you'll often see in
conceptual tutorials. You'll see how I integrate dependent types, type-driven
development, mutable data structures, generating random data, and preparation
for parallelism. I have been meaning to shift away from ``conceptual'' posts and
instead post a bit more about small, practical snippets that demonstrate some
useful Haskell techniques and principles drive how I approach coding in Haskell
overall.

For reference, the intended audience is for people with knowledge of Haskell
syntax and basic idioms (mapping, traversing, folding, applicatives). The source
code
\href{https://github.com/mstksg/inCode/tree/master/code-samples/kmeans/kmeans.hs}{is
online here}, and is structured as a nix flake script. If you have
\href{https://nixos.org/}{nix} installed (and flakes enabled), you should be
able to run the script as an executable (\texttt{./kmeans.hs}). You can also
load it for editing with \texttt{nix\ develop} + \texttt{ghci}.

\section{The Algorithm}\label{the-algorithm}

\href{https://en.wikipedia.org/wiki/K-means_clustering}{K-means} is a method of
assigning a bunch of data points and samples into \emph{k} clusters. For the
purpose of this post, we're going to talk about data points as points in a
vector space and clustering as grouping together clusters of points that are
close to each other (using Euclidean/L2 distance).

The basic iteration goes like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start with \emph{k} cluster centers (``means'', or ``centroids'' sometimes),
  \emph{k} arbitrary points in your space.
\item
  Repeat until the stop condition:

  \begin{itemize}
  \tightlist
  \item
    Assign/bucket each data point to its closest cluster center/mean.
  \item
    Move each of the cluster centers to the mean/centroid of the points that
    were assigned to it, or the points in its bucket.
  \end{itemize}
\end{enumerate}

Basically, we repeatedly say, ``if this was the true cluster center, what points
would be in it?''. Then we adjust our cluster center to the center of those
points that were assigned to it, updating to a better guess. Then we repeat
again. A simple stopping condition would be if none of the \emph{k} centers move
after the update step.

The algorithm leaves the assigning of the original points undefined, and it's
also not optimal either, since it might converge on clusters that aren't the
best. But it's simple enough conceptually that it's taught in every beginner
machine learning course.

\section{The Haskell}\label{the-haskell}

We're going to be dealing with points in a vector space and distances between
them, so a good thing to reach for is the
\emph{\href{http://hackage.haskell.org/package/linear}{linear}} library, which
offers types for 2D vectors, 3D vectors, etc. and how to deal with them as
points in a vector space. \emph{linear} offers an abstraction over multiple
vector space points. A point has type \texttt{p\ a}: \texttt{p} is a vector
space over field \texttt{a}. The library has \texttt{V2\ a} for 2D points, so
\texttt{V2\ Double} is \emph{essentially} \(\mathbb{R}^2\), a 2 dimensional
point with double-valued components.

We want a collection of \texttt{k} cluster centers. We can use
\emph{\href{http://hackage.haskell.org/package/vector-sized}{vector-sized}} for
a fixed-size collection of items, \texttt{Vector\ k\ (V2\ Double)} for
\texttt{k} 2-D double points, or \texttt{Vector\ k\ (p\ a)} for \texttt{k} of
any type of points.\footnote{Be mindful, for \texttt{Vector} here we are using
  things strictly as a ``fixed-sized collection of values'', whereas for
  \emph{linear}, we have types like \texttt{V2} which represent \emph{points in
  a mathematical vector space}. It's a bit unfortunate that the terminology
  overlaps here a bit.}

So overall, our function will have type:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{kMeans ::}\NormalTok{ [p a] }\OtherTok{{-}\textgreater{}} \DataTypeTok{Vector}\NormalTok{ k (p a)}
\end{Highlighting}
\end{Shaded}

It will take a collection of \texttt{p\ a} points, and provide the \texttt{k}
cluster centers. Note here that we have ``return-type polymorphism'', where the
\texttt{k} (number of items) is determined by what type the user expects the
function to return. If they want 3 clusters of 2d points, they will call it
expecting \texttt{Vector\ 3\ (V2\ Double)}. If they want 10 clusters of 2d
points, they would call it expecting \texttt{Vector\ 10\ (V2\ Double)}.

We take a \emph{list} of \texttt{p\ a}'s here because all we are going to do is
\emph{iterate} over each one\ldots we don't really care about random access or
updates, so it's really the best we can hope for, asymptotically\footnote{Yes,
  yes, linked lists are notoriously bad for the CPU-level cache and branch
  prediction, so if we are in a situation where we really care, using a
  contiguous memory data structure (like Storable Vector) might be better.}.

We have some leeway as to how we initialize our initial clusters. One simple
solution is to just assign point 0 to cluster 0, point 1 to cluster, point 2 to
cluster 2, etc., cycling around the clusters.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L33{-}L42}

\OtherTok{initialClusters ::}\NormalTok{ (}\DataTypeTok{Additive}\NormalTok{ p, }\DataTypeTok{Fractional}\NormalTok{ a, }\DataTypeTok{KnownNat}\NormalTok{ k) }\OtherTok{=\textgreater{}}\NormalTok{ [p a] }\OtherTok{{-}\textgreater{}} \DataTypeTok{Vector}\NormalTok{ k (p a)}
\NormalTok{initialClusters pts }\OtherTok{=}\NormalTok{ runST }\KeywordTok{do}
\NormalTok{  sums }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate zero}
\NormalTok{  counts }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate }\DecValTok{0}
\NormalTok{  ifor\_ pts \textbackslash{}i p }\OtherTok{{-}\textgreater{}} \KeywordTok{do}
    \KeywordTok{let}\NormalTok{ i\textquotesingle{} }\OtherTok{=}\NormalTok{ modulo (}\FunctionTok{fromIntegral}\NormalTok{ i)}
\NormalTok{    MV.modify sums (}\OperatorTok{\^{}+\^{}}\NormalTok{ p) i\textquotesingle{}}
\NormalTok{    MV.modify counts (}\OperatorTok{+} \DecValTok{1}\NormalTok{) i\textquotesingle{}}
\NormalTok{  V.generateM \textbackslash{}i }\OtherTok{{-}\textgreater{}}
\NormalTok{    (}\OperatorTok{\^{}/}\NormalTok{) }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ MV.read sums i }\OperatorTok{\textless{}*\textgreater{}}\NormalTok{ (}\FunctionTok{fromInteger} \OperatorTok{\textless{}$\textgreater{}}\NormalTok{ MV.read counts i)}
\end{Highlighting}
\end{Shaded}

\texttt{runST} runs the mutable algorithm where we initialize a vector of point
sums and a vector of point counts. We then iterate over all of the points with
their index (with \texttt{ifor\_}), and we add that point to the index of the
cluster, modulo \texttt{k}. A sized vector \texttt{Vector\ k\ a} is indexed by a
\texttt{Finite\ k} (an integer from 0 to \emph{k-1}). So,
\texttt{modulo\ ::\ Integer\ -\textgreater{}\ Finite\ k} will convert an integer
index to the \texttt{Finite\ k} index type, using modulus to wrap it around if
it's too big.

Here we are using some functions from \emph{linear}:

\begin{itemize}
\tightlist
\item
  \texttt{(\^{}+\^{})\ ::\ (Additive\ p,\ Num\ a)\ =\textgreater{}\ p\ a\ -\textgreater{}\ p\ a\ -\textgreater{}\ p\ a}
  which adds together two points
\item
  \texttt{(\^{}/)\ ::\ (Functor\ p,\ Fractional\ a)\ =\textgreater{}\ p\ a\ -\textgreater{}\ a\ -\textgreater{}\ p\ a}
  which divides a point by a scalar
\end{itemize}

At the end of it all, we use \texttt{V.generateM} to assemble our final
(immutable) centroids by reading out the sums and totals at each cluster:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V.generateM}\OtherTok{ ::}\NormalTok{ (}\DataTypeTok{Finite}\NormalTok{ k }\OtherTok{{-}\textgreater{}}\NormalTok{ m a) }\OtherTok{{-}\textgreater{}}\NormalTok{ m (}\DataTypeTok{Vector}\NormalTok{ k a)}
\end{Highlighting}
\end{Shaded}

Note that the lengths of our intermediate vectors (\texttt{sums},
\texttt{counts}, and the final result) are all implicitly inferred through type
inference (by \texttt{k}).

We can actually do a similar loop to assign/bin each point and compute the new
centroids:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L44{-}L61}

\OtherTok{moveClusters ::}
  \KeywordTok{forall}\NormalTok{ k p a}\OperatorTok{.}
\NormalTok{  (}\DataTypeTok{Metric}\NormalTok{ p, }\DataTypeTok{Floating}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ a, }\DataTypeTok{KnownNat}\NormalTok{ k, }\DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ k) }\OtherTok{=\textgreater{}}
\NormalTok{  [p a] }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ k (p a) }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ k (p a)}
\NormalTok{moveClusters pts origCentroids }\OtherTok{=}\NormalTok{ runST }\KeywordTok{do}
\NormalTok{  sums }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate zero}
\NormalTok{  counts }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate }\DecValTok{0}
\NormalTok{  for\_ pts \textbackslash{}p }\OtherTok{{-}\textgreater{}} \KeywordTok{do}
    \KeywordTok{let}\NormalTok{ closestIx }\OtherTok{=}\NormalTok{ V.minIndex }\OperatorTok{@}\NormalTok{a }\OperatorTok{@}\NormalTok{(k }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) (distance p }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ origCentroids)}
\NormalTok{    MV.modify sums (}\OperatorTok{\^{}+\^{}}\NormalTok{ p) closestIx}
\NormalTok{    MV.modify counts (}\OperatorTok{+} \DecValTok{1}\NormalTok{) closestIx}
\NormalTok{  V.generateM \textbackslash{}i }\OtherTok{{-}\textgreater{}} \KeywordTok{do}
\NormalTok{    n }\OtherTok{\textless{}{-}}\NormalTok{ MV.read counts i}
    \KeywordTok{if}\NormalTok{ n }\OperatorTok{==} \DecValTok{0}
      \KeywordTok{then} \FunctionTok{pure} \OperatorTok{$}\NormalTok{ origCentroids }\OtherTok{\textasciigrave{}V.index\textasciigrave{}}\NormalTok{ i}
      \KeywordTok{else}\NormalTok{ (}\OperatorTok{\^{}/} \FunctionTok{fromInteger}\NormalTok{ n) }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ MV.read sums i}
\end{Highlighting}
\end{Shaded}

We just have to be careful to not move the centroid if there are no points
assigned to it, otherwise we'd be dividing by 0.

Notice there's also something a little subtle going on with \texttt{closestIx},
which exposes a bit of the awkwardness with working with type-level numbers in
Haskell today. The type of \texttt{V.minIndex} is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V.minIndex}\OtherTok{ ::} \KeywordTok{forall}\NormalTok{ a n}\OperatorTok{.} \DataTypeTok{Ord}\NormalTok{ a }\OtherTok{=\textgreater{}} \DataTypeTok{Vector}\NormalTok{ (n }\OperatorTok{+} \DecValTok{1}\NormalTok{) a }\OtherTok{{-}\textgreater{}} \DataTypeTok{Finite}\NormalTok{ (n }\OperatorTok{+} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is because we only ever get a minimum if the vector is non-empty. So the
library takes \texttt{n\ +\ 1} as the size to ensure that only positive length
vectors are passed.

In our case, we want \texttt{V.minIndex\ blah\ ::\ Finite\ k}. However, remember
how typechecking works: we need to unify the type variables \texttt{a} and
\texttt{n} so that \texttt{n\ +\ 1} is equal to \texttt{k}. So, what does
\emph{n} have to be so that \(n + 1 = k\)? Well, we can see from algebra that
\texttt{n} needs to be \texttt{k\ -\ 1}: \texttt{(k\ -\ 1)\ +\ 1} is equal to
\texttt{k}. However, GHC is a little dumb-dumb here in that it cannot solve for
\texttt{n} itself. We can explicitly pass in \texttt{@(k\ -\ 1)} to say that
\texttt{n} has to be \texttt{k\ -\ 1}.

For this to work we need to pull in a GHC plugin
\href{http://hackage.haskell.org/package/ghc-typelits-natnormalise}{ghc-typelits-natnormalise}
which will allow GHC to simplify \texttt{(k\ -\ 1)\ +\ 1} to be \texttt{k},
which it can't do by itself for some reason. It also requires the constraint
that \texttt{1\ \textless{}=\ k} in order for \texttt{k\ -\ 1} to make sense for
natural number \texttt{k}. We can pull in the plugin with:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{\{{-}\# OPTIONS\_GHC {-}fplugin GHC.TypeLits.Normalise \#{-}\}}
\end{Highlighting}
\end{Shaded}

Honestly if we were to design the library from scratch today, I'd define it as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{V.minIndex}\OtherTok{ ::} \KeywordTok{forall}\NormalTok{ a n}\OperatorTok{.}\NormalTok{ (}\DataTypeTok{Ord}\NormalTok{ a, }\DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ n) }\OtherTok{=\textgreater{}} \DataTypeTok{Vector}\NormalTok{ n a }\OtherTok{{-}\textgreater{}} \DataTypeTok{Finite}\NormalTok{ n}
\end{Highlighting}
\end{Shaded}

in the first place, and we wouldn't need the typechecker plugin.

Anyway so that's the whole thing:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L63{-}L75}

\OtherTok{kMeans ::}
  \KeywordTok{forall}\NormalTok{ k p a}\OperatorTok{.}
\NormalTok{  (}\DataTypeTok{Metric}\NormalTok{ p, }\DataTypeTok{Floating}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ a, }\DataTypeTok{Eq}\NormalTok{ (p a), }\DataTypeTok{KnownNat}\NormalTok{ k, }\DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ k) }\OtherTok{=\textgreater{}}
\NormalTok{  [p a] }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ k (p a)}
\NormalTok{kMeans pts }\OtherTok{=}\NormalTok{ go }\DecValTok{0}\NormalTok{ (initialClusters pts)}
  \KeywordTok{where}
\OtherTok{    go ::} \DataTypeTok{Int} \OtherTok{{-}\textgreater{}} \DataTypeTok{Vector}\NormalTok{ k (p a) }\OtherTok{{-}\textgreater{}} \DataTypeTok{Vector}\NormalTok{ k (p a)}
\NormalTok{    go }\OperatorTok{!}\NormalTok{i }\OperatorTok{!}\NormalTok{cs}
      \OperatorTok{|}\NormalTok{ cs }\OperatorTok{==}\NormalTok{ cs\textquotesingle{} }\OperatorTok{||}\NormalTok{ i }\OperatorTok{\textgreater{}} \DecValTok{100} \OtherTok{=}\NormalTok{ cs}
      \OperatorTok{|} \FunctionTok{otherwise} \OtherTok{=}\NormalTok{ go (i }\OperatorTok{+} \DecValTok{1}\NormalTok{) cs\textquotesingle{}}
      \KeywordTok{where}
\NormalTok{        cs\textquotesingle{} }\OtherTok{=}\NormalTok{ moveClusters pts cs}
\end{Highlighting}
\end{Shaded}

Note I also added a stop after 100 steps, just to be safe.

\subsection{Type-Level Advantages and
Usability}\label{type-level-advantages-and-usability}

Having \texttt{k} in the type is useful for many reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  It helps us ensure that \texttt{moveClusters} doesn't change the number of
  clusters/centroids. If it was just
  \texttt{{[}p\ a{]}\ -\textgreater{}\ {[}p\ a{]}} we cannot guarantee that it
  does not add or drop clusters.
\item
  The type system means we don't have to manually pass \texttt{int} sizes
  around. For example, in \texttt{initialClusters}, we implicitly pass the size
  around \emph{four times} when we do \texttt{MV.replicate} (twice),
  \texttt{modulo}, and \texttt{generateM}! And, in the definition of
  \texttt{kMeans}, we implicitly pass it on to our call to
  \texttt{initialClusters}.
\item
  We don't have to worry about out-of-bounds indexing because any indices we
  generate (using \texttt{modular} or \texttt{minIndex}) are guaranteed (by
  their types) to be valid.
\item
  It's useful for the caller to guarantee they are getting what they are asking
  for. If
  \texttt{kMeans\ ::\ Int\ -\textgreater{}\ {[}p\ a{]}\ -\textgreater{}\ {[}p\ a{]}},
  then we (as the caller) can't be sure that the result list has the number of
  items that we requested. But because we have
  \texttt{kMeans\ ::\ {[}p\ a{]}\ -\textgreater{}\ Vector\ k\ (p\ a)}, the
  compiler ensures that the result has \emph{k} items.
\end{enumerate}

However you won't \emph{always} be able to necessarily put in a literal
\texttt{3} in \texttt{Vector\ 3\ (V2\ Double)}. Maybe your \emph{k} comes from a
configuration file or something else you pull in at runtime. We need a way to
call \texttt{kMeans} with just an \texttt{Int}! (also known as ``reification'')

Normally, this means using \texttt{someNatVal} to convert a value-level
\texttt{Natural} into a type-level \texttt{Nat}. However, in this case we have
to be a bit more careful because \emph{k} must be at least 1. As of GHC 9.2, we
can use \texttt{cmpNat} (before this, you could use
\href{http://hackage.haskell.org/package/typelits-witnesses}{typelits-witnesses})
to bring this constraint into scope.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L77{-}L87}

\OtherTok{kMeans\textquotesingle{} ::}
  \KeywordTok{forall}\NormalTok{ p a}\OperatorTok{.}
\NormalTok{  (}\DataTypeTok{Metric}\NormalTok{ p, }\DataTypeTok{Floating}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ a, }\DataTypeTok{Eq}\NormalTok{ (p a)) }\OtherTok{=\textgreater{}}
  \DataTypeTok{Natural} \OtherTok{{-}\textgreater{}}
\NormalTok{  [p a] }\OtherTok{{-}\textgreater{}}
\NormalTok{  [p a]}
\NormalTok{kMeans\textquotesingle{} k pts }\OtherTok{=} \KeywordTok{case}\NormalTok{ someNatVal k }\KeywordTok{of}
  \DataTypeTok{SomeNat} \OperatorTok{@}\NormalTok{k pk }\OtherTok{{-}\textgreater{}} \KeywordTok{case}\NormalTok{ cmpNat (}\DataTypeTok{Proxy} \OperatorTok{@}\DecValTok{1}\NormalTok{) pk }\KeywordTok{of}
    \DataTypeTok{LTI} \OtherTok{{-}\textgreater{}}\NormalTok{ toList }\OperatorTok{$}\NormalTok{ kMeans }\OperatorTok{@}\NormalTok{k pts }\CommentTok{{-}{-} 1 \textless{} k, so 1 \textless{}= k is valid}
    \DataTypeTok{EQI} \OtherTok{{-}\textgreater{}}\NormalTok{ toList }\OperatorTok{$}\NormalTok{ kMeans }\OperatorTok{@}\NormalTok{k pts }\CommentTok{{-}{-} 1 == k, so 1 \textless{}= k is valid}
    \DataTypeTok{GTI} \OtherTok{{-}\textgreater{}}\NormalTok{ [] }\CommentTok{{-}{-} in this branch, 1 \textgreater{} k, so we cannot call kMeans}
\end{Highlighting}
\end{Shaded}

\subsection{Applying the Clusters}\label{applying-the-clusters}

Of course, \texttt{kMeans} only gets us our centroids, so it would be useful to
actually create the clusters themselves and all their member points. We can do
something similar to what we did before with \texttt{ST} and mutable vectors and
\texttt{runST}, but life is too short to always be using mutable state. Let's
instead build up a map of indices to all the points that are closest to that
index. Then we use
\texttt{generate\ ::\ (Finite\ k\ -\textgreater{}\ a)\ -\textgreater{}\ Vector\ k\ a}
to create a vector by picking out the maps' value at the index at each spot in
the vector. Again here we see that the type system helps us by not having to
manually pass in a size, and \texttt{generate} giving us indices \texttt{i} that
match the number of the centroids we are grouping on.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L104{-}L119}

\OtherTok{applyClusters ::}
  \KeywordTok{forall}\NormalTok{ k p a}\OperatorTok{.}
\NormalTok{  (}\DataTypeTok{Metric}\NormalTok{ p, }\DataTypeTok{Floating}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ (p a), }\DataTypeTok{KnownNat}\NormalTok{ k, }\DecValTok{1} \OperatorTok{\textless{}=}\NormalTok{ k) }\OtherTok{=\textgreater{}}
\NormalTok{  [p a] }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ k (p a) }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ k (}\DataTypeTok{Set}\NormalTok{ (p a))}
\NormalTok{applyClusters pts cs }\OtherTok{=}\NormalTok{ V.generate \textbackslash{}i }\OtherTok{{-}\textgreater{}}\NormalTok{ M.findWithDefault S.empty i pointsClosestTo}
  \KeywordTok{where}
\OtherTok{    pointsClosestTo ::} \DataTypeTok{Map}\NormalTok{ (}\DataTypeTok{Finite}\NormalTok{ k) (}\DataTypeTok{Set}\NormalTok{ (p a))}
\NormalTok{    pointsClosestTo }\OtherTok{=}
\NormalTok{      M.fromListWith}
\NormalTok{        (}\OperatorTok{\textless{}\textgreater{}}\NormalTok{)}
\NormalTok{        [ (closestIx, S.singleton p)}
        \OperatorTok{|}\NormalTok{ p }\OtherTok{\textless{}{-}}\NormalTok{ pts}
\NormalTok{        , }\KeywordTok{let}\NormalTok{ closestIx }\OtherTok{=}\NormalTok{ V.minIndex }\OperatorTok{@}\NormalTok{a }\OperatorTok{@}\NormalTok{(k }\OperatorTok{{-}} \DecValTok{1}\NormalTok{) (distance p }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ cs)}
\NormalTok{        ]}
\end{Highlighting}
\end{Shaded}

\subsection{Parallelization}\label{parallelization}

Typically we parallelize this by assigning each worker thread a chunk of points
it has to deal with, and having each one compute sums and counts and
coordinating it all back in the end. In this case we want to keep the
intermediate sums and counts:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L89{-}L102}

\OtherTok{groupAndSum ::}
\NormalTok{  (}\DataTypeTok{Metric}\NormalTok{ p, }\DataTypeTok{Floating}\NormalTok{ a, }\DataTypeTok{Ord}\NormalTok{ a, }\DataTypeTok{KnownNat}\NormalTok{ (k }\OperatorTok{+} \DecValTok{1}\NormalTok{)) }\OtherTok{=\textgreater{}}
\NormalTok{  [p a] }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ (k }\OperatorTok{+} \DecValTok{1}\NormalTok{) (p a) }\OtherTok{{-}\textgreater{}}
  \DataTypeTok{Vector}\NormalTok{ (k }\OperatorTok{+} \DecValTok{1}\NormalTok{) (p a, }\DataTypeTok{Integer}\NormalTok{)}
\NormalTok{groupAndSum pts cs0 }\OtherTok{=}\NormalTok{ runST }\KeywordTok{do}
\NormalTok{  sums }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate zero}
\NormalTok{  counts }\OtherTok{\textless{}{-}}\NormalTok{ MV.replicate }\DecValTok{0}
\NormalTok{  for\_ pts \textbackslash{}p }\OtherTok{{-}\textgreater{}} \KeywordTok{do}
    \KeywordTok{let}\NormalTok{ closestIx }\OtherTok{=}\NormalTok{ V.minIndex (distance p }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ cs0)}
\NormalTok{    MV.modify sums (}\OperatorTok{\^{}+\^{}}\NormalTok{ p) closestIx}
\NormalTok{    MV.modify counts (}\OperatorTok{+} \DecValTok{1}\NormalTok{) closestIx}
\NormalTok{  V.generateM \textbackslash{}i }\OtherTok{{-}\textgreater{}}
\NormalTok{    (,) }\OperatorTok{\textless{}$\textgreater{}}\NormalTok{ MV.read sums i }\OperatorTok{\textless{}*\textgreater{}}\NormalTok{ MV.read counts i}
\end{Highlighting}
\end{Shaded}

\section{Running an example}\label{running-an-example}

For funsies let us generate sample points that we know are clustered based on k
random cluster centers, using
\href{http://hackage.haskell.org/package/mwc-random}{mwc-random} for randomness.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L121{-}L147}

\OtherTok{generateSamples ::}
  \KeywordTok{forall}\NormalTok{ p g m}\OperatorTok{.}
\NormalTok{  (}\DataTypeTok{Applicative}\NormalTok{ p, }\DataTypeTok{Traversable}\NormalTok{ p, }\DataTypeTok{StatefulGen}\NormalTok{ g m) }\OtherTok{=\textgreater{}}
  \CommentTok{{-}{-} | number of points per cluster}
  \DataTypeTok{Int} \OtherTok{{-}\textgreater{}}
  \CommentTok{{-}{-} | number of clusters}
  \DataTypeTok{Int} \OtherTok{{-}\textgreater{}}
\NormalTok{  g }\OtherTok{{-}\textgreater{}}
\NormalTok{  m ([p }\DataTypeTok{Double}\NormalTok{], [p }\DataTypeTok{Double}\NormalTok{])}
\NormalTok{generateSamples numPts numClusters g }\OtherTok{=} \KeywordTok{do}
\NormalTok{  (centers, ptss) }\OtherTok{\textless{}{-}}
    \FunctionTok{unzip} \OperatorTok{\textless{}$\textgreater{}}\NormalTok{ replicateM numClusters }\KeywordTok{do}
      \CommentTok{{-}{-} generate the centroid uniformly in the box component{-}by{-}component}
\NormalTok{      center }\OtherTok{\textless{}{-}} \FunctionTok{sequenceA} \OperatorTok{$} \FunctionTok{pure} \OperatorTok{@}\NormalTok{p }\OperatorTok{$}\NormalTok{ MWC.uniformRM (}\DecValTok{0}\NormalTok{, boxSize) g}
      \CommentTok{{-}{-} generate numPts points...}
\NormalTok{      pts }\OtherTok{\textless{}{-}}
\NormalTok{        replicateM numPts }\OperatorTok{$}
          \CommentTok{{-}{-} .. component{-}by{-}component, as normal distribution around the center}
          \FunctionTok{traverse}\NormalTok{ (\textbackslash{}c }\OtherTok{{-}\textgreater{}}\NormalTok{ MWC.normal c }\FloatTok{0.1}\NormalTok{ g) center}
      \FunctionTok{pure}\NormalTok{ (center, pts)}
  \FunctionTok{pure}\NormalTok{ (centers, }\FunctionTok{concat}\NormalTok{ ptss)}
  \KeywordTok{where}
    \CommentTok{{-}{-} get the dimension by getting the length of a unit point}
\NormalTok{    dim }\OtherTok{=} \FunctionTok{length}\NormalTok{ (}\FunctionTok{pure}\OtherTok{ () ::}\NormalTok{ p ())}
    \CommentTok{{-}{-} approximately scale the range of the numbers by the area that the}
    \CommentTok{{-}{-} clusters would take up}
\NormalTok{    boxSize }\OtherTok{=}\NormalTok{ (}\FunctionTok{fromIntegral}\NormalTok{ numClusters }\OperatorTok{**} \FunctionTok{recip}\NormalTok{ (}\FunctionTok{fromIntegral}\NormalTok{ dim)) }\OperatorTok{*} \DecValTok{20}
\end{Highlighting}
\end{Shaded}

By the way isn't it funny that everything just ends up being \texttt{traverse}
or some derivation of it (like \texttt{replicateM} or \texttt{sequenceA})?
Anyways,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} source: https://github.com/mstksg/inCode/tree/master/code{-}samples/kmeans/kmeans.hs\#L149{-}L158}

\OtherTok{main ::} \DataTypeTok{IO}\NormalTok{ ()}
\NormalTok{main }\OtherTok{=} \KeywordTok{do}
\NormalTok{  g }\OtherTok{\textless{}{-}}\NormalTok{ MWC.createSystemRandom}
\NormalTok{  (centers, samps) }\OtherTok{\textless{}{-}}\NormalTok{ generateSamples }\OperatorTok{@}\DataTypeTok{V2} \DecValTok{10} \DecValTok{3}\NormalTok{ g}
  \FunctionTok{putStrLn} \StringTok{"* points"}
  \FunctionTok{mapM\_} \FunctionTok{print}\NormalTok{ samps}
  \FunctionTok{putStrLn} \StringTok{"* actual centers"}
  \FunctionTok{print}\NormalTok{ centers}
  \FunctionTok{putStrLn} \StringTok{"* kmeans centers"}
  \FunctionTok{print} \OperatorTok{$}\NormalTok{ kMeans\textquotesingle{} }\DecValTok{3}\NormalTok{ samps}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
* points
V2 15.117809404050517 2.4824833627968137
V2 14.825686288414198 2.569457175505424
V2 14.806948346588289 2.3222471406644867
V2 15.012490917145703 2.41735577349797
V2 15.007612893836304 2.3823051676970746
V2 14.866016893659538 2.590777185848723
V2 14.83908442030534 2.5756382736578343
V2 14.969996769619264 2.549568226274995
V2 14.983371307935904 2.4823314218207586
V2 14.931617828479244 2.469607213743923
V2 29.426938075603196 9.90899836541481
V2 29.657363050066813 9.844458859292706
V2 29.487332896419872 9.65240948313236
V2 29.717470180982964 9.756325723236502
V2 29.67198068295402 9.688676918673274
V2 29.564673351390947 9.63896189703656
V2 29.56057222121772 9.833541221236656
V2 29.563747509453506 9.75593412158655
V2 29.497322568720026 9.684752183878274
V2 29.598339480038018 9.968546198295204
V2 3.204536005881443 30.039372398954175
V2 3.1684921057193005 30.082909536200095
V2 3.2040077021183793 29.90694542057959
V2 3.151859377604784 29.89198303817146
V2 3.1027920089123935 30.240061564528673
V2 3.2323285236152937 30.037812094337777
V2 3.2722229374242366 30.05215727709455
V2 2.9723263815754652 30.06281544324189
V2 3.1935700833126437 30.068367400732857
V2 3.253701544151972 29.875079507116222
* actual centers
[V2 14.938139892220267 2.4859265040850276,V2 29.55811494146035 9.808348344980386,V2 3.239842205071254 30.070304958459946]
* kmeans centers
[V2 14.936063507003428 2.484177094150801,V2 29.57457400168471 9.773260497178288,V2 3.175583667031591 30.025750368095725]
\end{verbatim}

Neat!

\section{Special Thanks}\label{special-thanks}

I am very humbled to be supported by an amazing community, who make it possible
for me to devote time to researching and writing these posts. Very special
thanks to my supporter at the ``Amazing'' level on
\href{https://www.patreon.com/justinle/overview}{patreon}, Josh Vera! :)

\section{Signoff}\label{signoff}

Hi, thanks for reading! You can reach me via email at
\href{mailto:justin@jle.im}{\nolinkurl{justin@jle.im}}, or at twitter at
\href{https://twitter.com/mstk}{@mstk}! This post and all others are published
under the \href{https://creativecommons.org/licenses/by-nc-nd/3.0/}{CC-BY-NC-ND
3.0} license. Corrections and edits via pull request are welcome and encouraged
at \href{https://github.com/mstksg/inCode}{the source repository}.

If you feel inclined, or this post was particularly helpful for you, why not
consider \href{https://www.patreon.com/justinle/overview}{supporting me on
Patreon}, or a \href{bitcoin:3D7rmAYgbDnp4gp4rf22THsGt74fNucPDU}{BTC donation}?
:)

\textbackslash end\{document\}

\end{document}
